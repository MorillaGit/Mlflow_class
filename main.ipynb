{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "# Import libraries\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.utils.validation import check_is_fitted\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from src import config, data_utils, preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "app_train, app_test, columns_description = data_utils.get_datasets()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train, X_test, y_test = data_utils.get_feature_target(app_train, app_test)\n",
    "X_train, X_val, y_train, y_val = data_utils.get_train_val_sets(X_train, y_train)\n",
    "train_data, val_data, test_data = preprocessing.preprocess_data(X_train, X_val, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\crist\\miniconda3\\envs\\gpu_base\\lib\\site-packages\\_distutils_hack\\__init__.py:30: UserWarning: Setuptools is replacing distutils.\n",
      "  warnings.warn(\"Setuptools is replacing distutils.\")\n"
     ]
    }
   ],
   "source": [
    "import mlflow\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "C= 0.0001\n",
    "max_iter= 1000\n",
    "random_state= 42\n",
    "\n",
    "with mlflow.start_run(run_name= \"Baseline\"):\n",
    "    log_reg = LogisticRegression(C=C,\n",
    "                                max_iter=max_iter,\n",
    "                                random_state=random_state)\n",
    "\n",
    "    log_reg.fit(train_data, y_train)\n",
    "\n",
    "    # log\n",
    "    mlflow.log_param(\"C\", C)\n",
    "    mlflow.log_param(\"max_iter\", 1000)\n",
    "    mlflow.log_param(\"random_state\", random_state)\n",
    "\n",
    "\n",
    "    # Calcular y registrar la métrica de precisión\n",
    "    train_preds = log_reg.predict(train_data)\n",
    "    train_accuracy = accuracy_score(y_train, train_preds)\n",
    "    mlflow.log_metric(\"train_accuracy\", train_accuracy)\n",
    "\n",
    "    # Registrar el modelo\n",
    "    mlflow.sklearn.log_model(log_reg, \"logistic_regression\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple LR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "\n",
    "C = 1\n",
    "max_iter = 1000\n",
    "random_state = 42\n",
    "\n",
    "with mlflow.start_run(run_name=\"LogisticRegression\"):\n",
    "    log_reg = LogisticRegression(C=C,\n",
    "                                  max_iter=max_iter,\n",
    "                                  random_state=random_state)\n",
    "\n",
    "    log_reg.fit(train_data, y_train)\n",
    "\n",
    "    # Log parameters\n",
    "    mlflow.log_param(\"Model\", \"LogisticRegression\")\n",
    "    mlflow.log_param(\"C\", C)\n",
    "    mlflow.log_param(\"max_iter\", max_iter)\n",
    "    mlflow.log_param(\"random_state\", random_state)\n",
    "\n",
    "    # Calcular y registrar la métrica de precisión\n",
    "    train_preds = log_reg.predict(train_data)\n",
    "    train_accuracy = accuracy_score(y_train, train_preds)\n",
    "    mlflow.log_metric(\"train_accuracy\", train_accuracy)\n",
    "\n",
    "    # Calcular y registrar el ROC AUC para el conjunto de entrenamiento\n",
    "    train_probs = log_reg.predict_proba(train_data)[:, 1]\n",
    "    train_roc_auc = roc_auc_score(y_train, train_probs)\n",
    "    mlflow.log_metric(\"train_roc_auc\", train_roc_auc)\n",
    "\n",
    "    # Registrar el modelo\n",
    "    mlflow.sklearn.log_model(log_reg, \"logistic_regression\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Medium - RFC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "def train_and_log_model(train_data, y_train, val_data, y_val, n_estimators, max_depth, random_state, run_name=\"Baseline\"):\n",
    "    with mlflow.start_run(run_name=run_name):\n",
    "        rf_clf = RandomForestClassifier(n_estimators=n_estimators,\n",
    "                                        max_depth=max_depth,\n",
    "                                        random_state=random_state)\n",
    "\n",
    "        rf_clf.fit(train_data, y_train)\n",
    "\n",
    "        mlflow.log_param(\"Model\", run_name)\n",
    "\n",
    "\n",
    "        # Log parameters\n",
    "        mlflow.log_param(\"n_estimators\", n_estimators)\n",
    "        mlflow.log_param(\"max_depth\", max_depth)\n",
    "        mlflow.log_param(\"random_state\", random_state)\n",
    "\n",
    "        # Calcular y registrar la métrica de precisión\n",
    "        train_preds = rf_clf.predict(train_data)\n",
    "        train_accuracy = accuracy_score(y_train, train_preds)\n",
    "        mlflow.log_metric(\"train_accuracy\", train_accuracy)\n",
    "\n",
    "        # Calcular y registrar el ROC AUC para el conjunto de entrenamiento\n",
    "        train_probs = rf_clf.predict_proba(train_data)[:, 1]\n",
    "        train_roc_auc = roc_auc_score(y_train, train_probs)\n",
    "        mlflow.log_metric(\"train_roc_auc\", train_roc_auc)\n",
    "\n",
    "        # Registrar el modelo\n",
    "        mlflow.sklearn.log_model(rf_clf, \"random_forest_classifier\")\n",
    "\n",
    "        # Calcular y registrar el ROC AUC para el conjunto de validación\n",
    "        val_probs = rf_clf.predict_proba(val_data)[:, 1]\n",
    "        val_roc_auc = roc_auc_score(y_val, val_probs)\n",
    "        mlflow.log_metric(\"val_roc_auc\", val_roc_auc)\n",
    "\n",
    "        print(f\"ROC AUC en el conjunto de validación: {val_roc_auc:.4f}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC en el conjunto de validación: 0.7151\n"
     ]
    }
   ],
   "source": [
    "# Ejemplo de uso de la función\n",
    "train_and_log_model(train_data, y_train, val_data, y_val, n_estimators=60, max_depth=5, random_state=42, run_name=\"RandomForestClassifier\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC en el conjunto de validación: 0.7047\n",
      "ROC AUC en el conjunto de validación: 0.7122\n",
      "ROC AUC en el conjunto de validación: 0.7117\n",
      "ROC AUC en el conjunto de validación: 0.7145\n",
      "ROC AUC en el conjunto de validación: 0.7171\n",
      "ROC AUC en el conjunto de validación: 0.7218\n",
      "ROC AUC en el conjunto de validación: 0.7245\n"
     ]
    }
   ],
   "source": [
    "list_max_depth_case = [1,2,3,4,5,6,7]\n",
    "\n",
    "for i in list_max_depth_case:\n",
    "    train_and_log_model(train_data, y_train, val_data, y_val, n_estimators=100, max_depth= i, random_state=42, run_name=\"RandomForestClassifier\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random search - RFC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "def train_and_log_model(train_data, y_train, val_data, y_val, n_iter, cv, random_state,\n",
    "                        n_estimators_range, max_depth_range, min_samples_split_values,\n",
    "                        min_samples_leaf_values, bootstrap_values, run_name=\"RandomizedSearchCV\"):\n",
    "    \n",
    "    param_grid = {\n",
    "        \"n_estimators\": n_estimators_range,\n",
    "        \"max_depth\": max_depth_range,\n",
    "        \"min_samples_split\": min_samples_split_values,\n",
    "        \"min_samples_leaf\": min_samples_leaf_values,\n",
    "        \"bootstrap\": bootstrap_values,\n",
    "    }\n",
    "\n",
    "    rf_random = RandomizedSearchCV(\n",
    "        estimator=RandomForestClassifier(),\n",
    "        param_distributions=param_grid,\n",
    "        n_iter=n_iter,\n",
    "        cv=cv,\n",
    "        verbose=2,\n",
    "        random_state=random_state,\n",
    "    )\n",
    "\n",
    "    with mlflow.start_run(run_name=run_name):\n",
    "        rf_random.fit(train_data, y_train)\n",
    "\n",
    "        best_params = rf_random.best_params_\n",
    "        best_rf_clf = rf_random.best_estimator_\n",
    "\n",
    "        # Log parameters\n",
    "        mlflow.log_param(\"Model\", run_name)\n",
    "        for param, value in best_params.items():\n",
    "            mlflow.log_param(param, value)\n",
    "\n",
    "        # Calcular y registrar la métrica de precisión\n",
    "        train_preds = best_rf_clf.predict(train_data)\n",
    "        train_accuracy = accuracy_score(y_train, train_preds)\n",
    "        mlflow.log_metric(\"train_accuracy\", train_accuracy)\n",
    "\n",
    "        # Calcular y registrar el ROC AUC para el conjunto de entrenamiento\n",
    "        train_probs = best_rf_clf.predict_proba(train_data)[:, 1]\n",
    "        train_roc_auc = roc_auc_score(y_train, train_probs)\n",
    "        mlflow.log_metric(\"train_roc_auc\", train_roc_auc)\n",
    "\n",
    "        # Registrar el modelo\n",
    "        mlflow.sklearn.log_model(best_rf_clf, \"random_forest_classifier\")\n",
    "\n",
    "        # Calcular y registrar el ROC AUC para el conjunto de validación\n",
    "        val_probs = best_rf_clf.predict_proba(val_data)[:, 1]\n",
    "        val_roc_auc = roc_auc_score(y_val, val_probs)\n",
    "        mlflow.log_metric(\"val_roc_auc\", val_roc_auc)\n",
    "\n",
    "        print(f\"ROC AUC en el conjunto de validación: {val_roc_auc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 2 candidates, totalling 4 fits\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=273; total time= 1.3min\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=273; total time= 1.3min\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=1, min_samples_split=2, n_estimators=1485; total time=12.2min\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=1, min_samples_split=2, n_estimators=1485; total time=11.2min\n",
      "ROC AUC en el conjunto de validación: 0.7324\n"
     ]
    }
   ],
   "source": [
    "# Ejemplo de uso de la función\n",
    "n_estimators_range = [int(x) for x in np.linspace(start=200, stop=2000, num=50)]\n",
    "max_depth_range = [int(x) for x in np.linspace(10, 50, num=5)]\n",
    "min_samples_split_values = [2, 5]\n",
    "min_samples_leaf_values = [1, 2]\n",
    "bootstrap_values = [True]\n",
    "\n",
    "train_and_log_model(train_data, y_train, val_data, y_val, n_iter=2, cv=2, random_state=42,\n",
    "                    n_estimators_range=n_estimators_range, max_depth_range=max_depth_range,\n",
    "                    min_samples_split_values=min_samples_split_values, min_samples_leaf_values=min_samples_leaf_values,\n",
    "                    bootstrap_values=bootstrap_values)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid search - RFC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 1000 candidates, totalling 2000 fits\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import mlflow\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "def train_and_log_model(train_data, y_train, val_data, y_val, cv, random_state,\n",
    "                        n_estimators_range, max_depth_range, min_samples_split_values,\n",
    "                        min_samples_leaf_values, bootstrap_values, run_name=\"GridSearchCV\"):\n",
    "    \n",
    "    param_grid = {\n",
    "        \"n_estimators\": n_estimators_range,\n",
    "        \"max_depth\": max_depth_range,\n",
    "        \"min_samples_split\": min_samples_split_values,\n",
    "        \"min_samples_leaf\": min_samples_leaf_values,\n",
    "        \"bootstrap\": bootstrap_values,\n",
    "    }\n",
    "\n",
    "    rf_grid = GridSearchCV(\n",
    "        estimator=RandomForestClassifier(),\n",
    "        param_grid=param_grid,\n",
    "        cv=cv,\n",
    "        verbose=2,\n",
    "        n_jobs=-1,\n",
    "    )\n",
    "\n",
    "    with mlflow.start_run(run_name=run_name):\n",
    "        rf_grid.fit(train_data, y_train)\n",
    "\n",
    "        best_params = rf_grid.best_params_\n",
    "        best_rf_clf = rf_grid.best_estimator_\n",
    "\n",
    "        # Log parameters\n",
    "        for param, value in best_params.items():\n",
    "            mlflow.log_param(param, value)\n",
    "\n",
    "        # Calcular y registrar la métrica de precisión en el conjunto de entrenamiento\n",
    "        train_preds = best_rf_clf.predict(train_data)\n",
    "        train_accuracy = accuracy_score(y_train, train_preds)\n",
    "        mlflow.log_metric(\"train_accuracy\", train_accuracy)\n",
    "\n",
    "        # Calcular y registrar el ROC AUC para el conjunto de entrenamiento\n",
    "        train_probs = best_rf_clf.predict_proba(train_data)[:, 1]\n",
    "        train_roc_auc = roc_auc_score(y_train, train_probs)\n",
    "        mlflow.log_metric(\"train_roc_auc\", train_roc_auc)\n",
    "\n",
    "        # Calcular y registrar la métrica de precisión en el conjunto de validación\n",
    "        val_preds = best_rf_clf.predict(val_data)\n",
    "        val_accuracy = accuracy_score(y_val, val_preds)\n",
    "        mlflow.log_metric(\"val_accuracy\", val_accuracy)\n",
    "\n",
    "        # Calcular y registrar el ROC AUC para el conjunto de validación\n",
    "        val_probs = best_rf_clf.predict_proba(val_data)[:, 1]\n",
    "        val_roc_auc = roc_auc_score(y_val, val_probs)\n",
    "        mlflow.log_metric(\"val_roc_auc\", val_roc_auc)\n",
    "\n",
    "        # Registrar el modelo\n",
    "        mlflow.sklearn.log_model(best_rf_clf, \"random_forest_classifier\")\n",
    "\n",
    "        print(f\"ROC AUC en el conjunto de validación: {val_roc_auc:.4f}\")\n",
    "\n",
    "# Ejemplo de uso de la función\n",
    "n_estimators_range = [int(x) for x in np.linspace(start=200, stop=2000, num=50)]\n",
    "max_depth_range = [int(x) for x in np.linspace(10, 50, num=5)]\n",
    "min_samples_split_values = [2, 5]\n",
    "min_samples_leaf_values = [1, 2]\n",
    "bootstrap_values = [True]\n",
    "\n",
    "train_and_log_model(train_data, y_train, val_data, y_val, cv=2, random_state=42,\n",
    "                    n_estimators_range=n_estimators_range, max_depth_range=max_depth_range,\n",
    "                    min_samples_split_values=min_samples_split_values, min_samples_leaf_values=min_samples_leaf_values,\n",
    "                    bootstrap_values=bootstrap_values)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "import lightgbm as lgb\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "\n",
    "def train_and_log_lightgbm(train_data, y_train, val_data, y_val, params, run_name=\"LightGBM\"):\n",
    "    \n",
    "    with mlflow.start_run(run_name=run_name):\n",
    "\n",
    "        # Crear el conjunto de datos de LightGBM\n",
    "        lgb_train_data = lgb.Dataset(train_data, label=y_train)\n",
    "        lgb_val_data = lgb.Dataset(val_data, label=y_val, reference=lgb_train_data)\n",
    "\n",
    "        mlflow.log_param(\"Model\", run_name)\n",
    "\n",
    "        # Entrenar el modelo LightGBM\n",
    "        lgb_model = lgb.train(params, lgb_train_data, valid_sets=lgb_val_data)\n",
    "\n",
    "        # Log parameters\n",
    "        for param, value in params.items():\n",
    "            mlflow.log_param(param, value)\n",
    "\n",
    "        # Calcular y registrar la métrica de precisión en el conjunto de entrenamiento\n",
    "        train_preds = np.round(lgb_model.predict(train_data))\n",
    "        train_accuracy = accuracy_score(y_train, train_preds)\n",
    "        mlflow.log_metric(\"train_accuracy\", train_accuracy)\n",
    "\n",
    "        # Calcular y registrar el ROC AUC para el conjunto de entrenamiento\n",
    "        train_probs = lgb_model.predict(train_data)\n",
    "        train_roc_auc = roc_auc_score(y_train, train_probs)\n",
    "        mlflow.log_metric(\"train_roc_auc\", train_roc_auc)\n",
    "\n",
    "        # Calcular y registrar la métrica de precisión en el conjunto de validación\n",
    "        val_preds = np.round(lgb_model.predict(val_data))\n",
    "        val_accuracy = accuracy_score(y_val, val_preds)\n",
    "        mlflow.log_metric(\"val_accuracy\", val_accuracy)\n",
    "\n",
    "        # Calcular y registrar el ROC AUC para el conjunto de validación\n",
    "        val_probs = lgb_model.predict(val_data)\n",
    "        val_roc_auc = roc_auc_score(y_val, val_probs)\n",
    "        mlflow.log_metric(\"val_roc_auc\", val_roc_auc)\n",
    "\n",
    "        # Registrar el modelo\n",
    "        mlflow.lightgbm.log_model(lgb_model, \"lightgbm\")\n",
    "\n",
    "        print(f\"ROC AUC en el conjunto de validación: {val_roc_auc:.4f}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "params = {\n",
    "    \"objective\": \"binary\",\n",
    "    \"metric\": \"auc\",\n",
    "    \"boosting_type\": \"gbdt\",\n",
    "    \"num_leaves\": 31,\n",
    "    \"learning_rate\": 0.05,\n",
    "    \"feature_fraction\": 0.9,\n",
    "}\n",
    "\n",
    "train_and_log_lightgbm(train_data, y_train, val_data, y_val, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "def train_and_log_xgboost(train_data, y_train, val_data, y_val, params, run_name=\"XGBoost\", artifact_path=\"artifact\"):\n",
    "    \n",
    "    with mlflow.start_run(run_name=run_name):\n",
    "\n",
    "        # Crear el conjunto de datos de XGBoost\n",
    "        xgb_train_data = xgb.DMatrix(train_data, label=y_train)\n",
    "        xgb_val_data = xgb.DMatrix(val_data, label=y_val)\n",
    "\n",
    "        # Entrenar el modelo XGBoost\n",
    "        xgb_model = xgb.train(params, xgb_train_data, evals=[(xgb_val_data, 'validation')])\n",
    "\n",
    "        # Log parameters\n",
    "        for param, value in params.items():\n",
    "            mlflow.log_param(param, value)\n",
    "\n",
    "        # Registrar el nombre del modelo\n",
    "        mlflow.log_param(\"Model\", run_name)\n",
    "\n",
    "        # Calcular y registrar la métrica de precisión en el conjunto de entrenamiento\n",
    "        train_preds = np.round(xgb_model.predict(xgb_train_data))\n",
    "        train_accuracy = accuracy_score(y_train, train_preds)\n",
    "        mlflow.log_metric(\"train_accuracy\", train_accuracy)\n",
    "\n",
    "        # Calcular y registrar el ROC AUC para el conjunto de entrenamiento\n",
    "        train_probs = xgb_model.predict(xgb_train_data)\n",
    "        train_roc_auc = roc_auc_score(y_train, train_probs)\n",
    "        mlflow.log_metric(\"train_roc_auc\", train_roc_auc)\n",
    "\n",
    "        # Calcular y registrar la métrica de precisión en el conjunto de validación\n",
    "        val_preds = np.round(xgb_model.predict(xgb_val_data))\n",
    "        val_accuracy = accuracy_score(y_val, val_preds)\n",
    "        mlflow.log_metric(\"val_accuracy\", val_accuracy)\n",
    "\n",
    "        # Calcular y registrar el ROC AUC para el conjunto de validación\n",
    "        val_probs = xgb_model.predict(xgb_val_data)\n",
    "        val_roc_auc = roc_auc_score(y_val, val_probs)\n",
    "        mlflow.log_metric(\"val_roc_auc\", val_roc_auc)\n",
    "\n",
    "        # Registrar el modelo\n",
    "        mlflow.xgboost.log_model(xgb_model, \"xgboost\")\n",
    "\n",
    "        # Guardar artefacto\n",
    "        os.makedirs(artifact_path, exist_ok=True)\n",
    "        \n",
    "        # Crear y guardar la matriz de confusión como imagen\n",
    "        cm = confusion_matrix(y_val, val_preds)\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
    "        plt.ylabel(\"True label\")\n",
    "        plt.xlabel(\"Predicted label\")\n",
    "        plt.title(\"Matriz de confusión\")\n",
    "        confusion_matrix_path = os.path.join(artifact_path, \"confusion_matrix.png\")\n",
    "        plt.savefig(confusion_matrix_path)\n",
    "        plt.close()\n",
    "\n",
    "        mlflow.log_artifacts(artifact_path)\n",
    "\n",
    "        # Eliminar el directorio del artefacto local después de registrar\n",
    "        shutil.rmtree(artifact_path)\n",
    "\n",
    "        print(f\"ROC AUC en el conjunto de validación: {val_roc_auc:.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "# Ejemplo de uso de la función\n",
    "params = {\n",
    "    \"objective\": \"binary:logistic\",\n",
    "    \"eval_metric\": \"auc\",\n",
    "        \"max_depth\": 6,\n",
    "    \"eta\": 0.3,\n",
    "    \"silent\": 1,\n",
    "}\n",
    "\n",
    "train_and_log_xgboost(train_data, y_train, val_data, y_val, params)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imagenes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "import os\n",
    "import sys\n",
    "\n",
    "\n",
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from src import data_utils, models, config\n",
    "\n",
    "# # /////////////////////////////////////////////////////////////////////////////////////////////\n",
    "\n",
    "from src import class_Experiment\n",
    "from src.class_Experiment import registrar_experiment\n",
    "from src import models, data_utils, config\n",
    "\n",
    "# /////////////////////////////////////////////////////////////////////////////////////////////\n",
    "\n",
    "DATASET_FOLDER = config.DATASET_FILENAME_IMAGE\n",
    "\n",
    "img_height = 224\n",
    "img_width = 224\n",
    "channels = 3\n",
    "batch_size = 32\n",
    "num_classes = 25\n",
    "\n",
    "input_shape = (img_height, img_width, channels)\n",
    "\n",
    "# Load train and test datasets\n",
    "train_ds = keras.preprocessing.image_dataset_from_directory(\n",
    "    directory=os.path.join(DATASET_FOLDER, \"train\"),\n",
    "    labels=\"inferred\",\n",
    "    label_mode=\"categorical\",\n",
    "    seed=123,\n",
    "    image_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    ")\n",
    "\n",
    "test_ds = keras.preprocessing.image_dataset_from_directory(\n",
    "    directory=os.path.join(DATASET_FOLDER, \"test\"),\n",
    "    labels=\"inferred\",\n",
    "    label_mode=\"categorical\",\n",
    "    seed=123,\n",
    "    image_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    ")\n",
    "\n",
    "class_names = train_ds.class_names\n",
    "print(class_names)\n",
    "\n",
    "assert len(class_names) == 25\n",
    "\n",
    "\n",
    "# Configure data loader for performance\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "train_ds = train_ds.cache().shuffle(1000).prefetch(buffer_size=AUTOTUNE)\n",
    "test_ds = test_ds.cache().prefetch(buffer_size=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " efficientnetb0 (Functional)  (None, 7, 7, 1280)       4049571   \n",
      "                                                                 \n",
      " flatten_3 (Flatten)         (None, 62720)             0         \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 32)                2007072   \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 32)                0         \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 25)                825       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 6,057,468\n",
      "Trainable params: 2,007,897\n",
      "Non-trainable params: 4,049,571\n",
      "_________________________________________________________________\n",
      "None\n",
      "Found 1875 images belonging to 25 classes.\n",
      "Found 7509 images belonging to 25 classes.\n",
      "Epoch 1/20\n",
      "235/235 [==============================] - 87s 350ms/step - loss: 3.2607 - accuracy: 0.0445 - val_loss: 3.1847 - val_accuracy: 0.0619\n",
      "Epoch 2/20\n",
      "235/235 [==============================] - 82s 348ms/step - loss: 3.1737 - accuracy: 0.0570 - val_loss: 3.1133 - val_accuracy: 0.0805\n",
      "Epoch 3/20\n",
      "235/235 [==============================] - 77s 328ms/step - loss: 3.1328 - accuracy: 0.0696 - val_loss: 3.0933 - val_accuracy: 0.0848\n",
      "Epoch 4/20\n",
      "235/235 [==============================] - 80s 339ms/step - loss: 3.0995 - accuracy: 0.0788 - val_loss: 3.0367 - val_accuracy: 0.0992\n",
      "Epoch 5/20\n",
      "235/235 [==============================] - 81s 343ms/step - loss: 3.0270 - accuracy: 0.0970 - val_loss: 2.9618 - val_accuracy: 0.1115\n",
      "Epoch 6/20\n",
      "235/235 [==============================] - 76s 323ms/step - loss: 2.9877 - accuracy: 0.1020 - val_loss: 2.9163 - val_accuracy: 0.1184\n",
      "Epoch 7/20\n",
      "235/235 [==============================] - 75s 317ms/step - loss: 2.9590 - accuracy: 0.1029 - val_loss: 2.9143 - val_accuracy: 0.1115\n",
      "Epoch 8/20\n",
      "235/235 [==============================] - 79s 338ms/step - loss: 2.9333 - accuracy: 0.1060 - val_loss: 2.8658 - val_accuracy: 0.1232\n",
      "Epoch 9/20\n",
      "235/235 [==============================] - 91s 389ms/step - loss: 2.9287 - accuracy: 0.1032 - val_loss: 2.8602 - val_accuracy: 0.1285\n",
      "Epoch 10/20\n",
      "235/235 [==============================] - 80s 341ms/step - loss: 2.8990 - accuracy: 0.1129 - val_loss: 2.8816 - val_accuracy: 0.1291\n",
      "Epoch 11/20\n",
      "235/235 [==============================] - 86s 366ms/step - loss: 2.8766 - accuracy: 0.1167 - val_loss: 2.8528 - val_accuracy: 0.1552\n",
      "Epoch 12/20\n",
      "235/235 [==============================] - 80s 339ms/step - loss: 2.8637 - accuracy: 0.1233 - val_loss: 2.8124 - val_accuracy: 0.1440\n",
      "Epoch 13/20\n",
      "235/235 [==============================] - 80s 342ms/step - loss: 2.8387 - accuracy: 0.1288 - val_loss: 2.7680 - val_accuracy: 0.1371\n",
      "Epoch 14/20\n",
      "235/235 [==============================] - ETA: 0s - loss: 2.8187 - accuracy: 0.1288"
     ]
    }
   ],
   "source": [
    "# /////////////////////////////////////////////////////////////////////////////////////////////\n",
    "# /////////////////////////////////////////////////////////////////////////////////////////////\n",
    "# /////////////////////////////////////////////////////////////////////////////////////////////\n",
    "# /////////////////////////////////////////////////////////////////////////////////////////////\n",
    "# Parámetros del experimento\n",
    "experiment_params = {\n",
    "    \"experiment_name\": \"CV\",\n",
    "    \"model_name\": \"efficientnet_B0\",\n",
    "    \"input_shape\": input_shape,\n",
    "    \"dropout\": 0.15,\n",
    "    \"num_classes\": len(class_names),\n",
    "    \"ruta_carpeta_train\": r\"C:\\Users\\crist\\Documents\\anyoneai\\sprint_4\\dataset\\eu-car-dataset_subset\\train\",\n",
    "    \"ruta_carpeta_test\": r\"C:\\Users\\crist\\Documents\\anyoneai\\sprint_4\\dataset\\eu-car-dataset_subset\\test\",\n",
    "    \"batch_size\": 32,\n",
    "    \"epochs\": 20,\n",
    "    \"data_augmentation\": True,\n",
    "    \"additional_layers\": 1,\n",
    "    \"neurons_per_layer\": [32],\n",
    "    \"hyperparameters\": {\n",
    "        \"optimizer\": \"adam\",\n",
    "        \"loss\": \"categorical_crossentropy\",\n",
    "        \"batch_size\": 32,\n",
    "        \"epochs\": 20,\n",
    "    },\n",
    "    \"metrics\": {\n",
    "        \"accuracy\": \"accuracy\",\n",
    "    },\n",
    "    \"augmentation_params\": {\n",
    "        \"rotation_range\": 10,\n",
    "        \"width_shift_range\": 0.2,\n",
    "        \"height_shift_range\": 0.1,\n",
    "        \"shear_range\": 0.2,\n",
    "        \"zoom_range\": 0.2,\n",
    "        \"horizontal_flip\": True,\n",
    "        \"fill_mode\": \"nearest\",\n",
    "    }\n",
    "}\n",
    "\n",
    "model = models.create_efficientnet_model_compiled(\n",
    "    version=0,\n",
    "    input_shape=experiment_params[\"input_shape\"],\n",
    "    debug=True,\n",
    "    dropout=experiment_params[\"dropout\"],\n",
    "    num_classes=experiment_params[\"num_classes\"],\n",
    "    additional_layers=experiment_params[\"additional_layers\"],\n",
    "    neurons_per_layer=experiment_params[\"neurons_per_layer\"]\n",
    "\n",
    ")\n",
    "\n",
    "experiment = class_Experiment.Experiment(\n",
    "    experiment_name=experiment_params[\"experiment_name\"],\n",
    "    model_name=experiment_params[\"model_name\"],\n",
    "    model=model,\n",
    "    hyperparameters=experiment_params[\"hyperparameters\"],\n",
    "    metrics=experiment_params[\"metrics\"],\n",
    "    ruta_carpeta_train=experiment_params[\"ruta_carpeta_train\"],\n",
    "    ruta_carpeta_test=experiment_params[\"ruta_carpeta_test\"],\n",
    "    batch_size=experiment_params[\"batch_size\"],\n",
    "    epochs=experiment_params[\"epochs\"],\n",
    "    data_augmentation=experiment_params[\"data_augmentation\"],\n",
    "    **experiment_params[\"augmentation_params\"]\n",
    ")\n",
    "\n",
    "class_Experiment.registrar_experiment(experiment, experiment_params[\"experiment_name\"])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpu_base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
