{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLFlow Class Experiment"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "# Import libraries\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.utils.validation import check_is_fitted\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from src import config, data_utils, preprocessing\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import mlflow\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "\n",
    "import mlflow\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "import mlflow\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "import mlflow\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "import mlflow\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import shutil\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "# Libraries for Data Manipulation and Visualization\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Import local modules\n",
    "from src import config, data_utils, preprocessing\n",
    "\n",
    "# Libraries for Model Training and Evaluation\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.utils.validation import check_is_fitted\n",
    "\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, confusion_matrix\n",
    "\n",
    "\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "\n",
    "\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "# Libraries for Experiment Tracking\n",
    "import mlflow\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "app_train, app_test, columns_description = data_utils.get_datasets()\n",
    "X_train, y_train, X_test, y_test = data_utils.get_feature_target(app_train, app_test)\n",
    "X_train, X_val, y_train, y_val = data_utils.get_train_val_sets(X_train, y_train)\n",
    "train_data, val_data, test_data = preprocessing.preprocess_data(X_train, X_val, X_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example, we'll demonstrate a simple experiment using MLflow. We'll be using a toy dataset and training a basic machine learning model. The goal is to showcase the usage of MLflow's `log_param`, `log_metric`, and `log_model` functionalities.\n",
    "\n",
    "- `log_param`: This function is used to log key-value pairs representing the hyperparameters used in our model. This allows us to keep track of different hyperparameter combinations used across various experiments.\n",
    "\n",
    "- `log_metric`: The `log_metric` function enables us to log the performance metrics of our model. This is useful for comparing different model iterations and understanding how well our model is performing.\n",
    "\n",
    "- `log_model`: With `log_model`, we can save our trained model, making it easier to share, reproduce, and deploy. This function stores the model's structure and learned parameters.\n",
    "\n",
    "Now, let's take a look at the code to see how these functions are used in practice.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "C= 0.0001\n",
    "max_iter= 1000\n",
    "random_state= 42\n",
    "\n",
    "with mlflow.start_run():\n",
    "    log_reg = LogisticRegression(C=C,\n",
    "                                max_iter=max_iter,\n",
    "                                random_state=random_state)\n",
    "\n",
    "    log_reg.fit(train_data, y_train)\n",
    "\n",
    "    # log\n",
    "    mlflow.log_param(\"C\", C)\n",
    "    mlflow.log_param(\"max_iter\", 1000)\n",
    "    mlflow.log_param(\"random_state\", random_state)\n",
    "\n",
    "\n",
    "    # Calcular y registrar la métrica de precisión\n",
    "    train_preds = log_reg.predict(train_data)\n",
    "    train_accuracy = accuracy_score(y_train, train_preds)\n",
    "    mlflow.log_metric(\"train_accuracy\", train_accuracy)\n",
    "\n",
    "    # Registrar el modelo\n",
    "    mlflow.sklearn.log_model(log_reg, \"logistic_regression\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple LR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set hyperparameters for the Logistic Regression model\n",
    "C = 1\n",
    "max_iter = 1000\n",
    "random_state = 42\n",
    "\n",
    "# Start an MLflow run to track the experiment\n",
    "with mlflow.start_run(run_name=\"LogisticRegression\"):\n",
    "    # Initialize the Logistic Regression model with the specified hyperparameters\n",
    "    log_reg = LogisticRegression(C=C,\n",
    "                                  max_iter=max_iter,\n",
    "                                  random_state=random_state)\n",
    "\n",
    "    # Train the model on the training data\n",
    "    log_reg.fit(train_data, y_train)\n",
    "\n",
    "    # Log the model's hyperparameters using mlflow.log_param()\n",
    "    mlflow.log_param(\"Model\", \"LogisticRegression\")\n",
    "    mlflow.log_param(\"C\", C)\n",
    "    mlflow.log_param(\"max_iter\", max_iter)\n",
    "    mlflow.log_param(\"random_state\", random_state)\n",
    "\n",
    "    # Calculate and log the accuracy metric on the training data using mlflow.log_metric()\n",
    "    train_preds = log_reg.predict(train_data)\n",
    "    train_accuracy = accuracy_score(y_train, train_preds)\n",
    "    mlflow.log_metric(\"train_accuracy\", train_accuracy)\n",
    "\n",
    "    # Calculate and log the ROC AUC metric on the training data using mlflow.log_metric()\n",
    "    train_probs = log_reg.predict_proba(train_data)[:, 1]\n",
    "    train_roc_auc = roc_auc_score(y_train, train_probs)\n",
    "    mlflow.log_metric(\"train_roc_auc\", train_roc_auc)\n",
    "\n",
    "    # Log the trained model itself using mlflow.sklearn.log_model()\n",
    "    mlflow.sklearn.log_model(log_reg, \"logistic_regression\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Medium - RFC"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this code snippet, we have encapsulated the process of training a Random Forest Classifier and logging the model parameters, metrics, and the model itself using MLflow within a function called train_and_log_model(). This function takes in the following inputs:\n",
    "\n",
    "train_data: The training dataset\n",
    "y_train: The target variable for the training dataset\n",
    "val_data: The validation dataset\n",
    "y_val: The target variable for the validation dataset\n",
    "n_estimators: The number of trees in the Random Forest\n",
    "max_depth: The maximum depth of the trees\n",
    "random_state: A seed for reproducibility\n",
    "run_name: A custom name for the MLflow run\n",
    "The function performs the following steps:\n",
    "\n",
    "Start an MLflow run with the specified run_name.\n",
    "Initialize and train the Random Forest Classifier with the given hyperparameters.\n",
    "Log the model's hyperparameters, accuracy, and ROC AUC metrics for both the training and validation datasets using MLflow.\n",
    "Log the trained model using mlflow.sklearn.log_model()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_log_model(train_data, y_train, val_data, y_val, n_estimators, max_depth, random_state, run_name=\"Baseline\"):\n",
    "    # Start an MLflow run with the specified run_name\n",
    "    with mlflow.start_run(run_name=run_name):\n",
    "        # Initialize and train the Random Forest Classifier with the given hyperparameters\n",
    "        rf_clf = RandomForestClassifier(n_estimators=n_estimators,\n",
    "                                        max_depth=max_depth,\n",
    "                                        random_state=random_state)\n",
    "        rf_clf.fit(train_data, y_train)\n",
    "\n",
    "        # Log the model's hyperparameters\n",
    "        mlflow.log_param(\"Model\", run_name)\n",
    "        mlflow.log_param(\"n_estimators\", n_estimators)\n",
    "        mlflow.log_param(\"max_depth\", max_depth)\n",
    "        mlflow.log_param(\"random_state\", random_state)\n",
    "\n",
    "        # Calculate and log the accuracy metric for the training dataset\n",
    "        train_preds = rf_clf.predict(train_data)\n",
    "        train_accuracy = accuracy_score(y_train, train_preds)\n",
    "        mlflow.log_metric(\"train_accuracy\", train_accuracy)\n",
    "\n",
    "        # Calculate and log the ROC AUC metric for the training dataset\n",
    "        train_probs = rf_clf.predict_proba(train_data)[:, 1]\n",
    "        train_roc_auc = roc_auc_score(y_train, train_probs)\n",
    "        mlflow.log_metric(\"train_roc_auc\", train_roc_auc)\n",
    "\n",
    "        # Log the trained model using mlflow.sklearn.log_model()\n",
    "        mlflow.sklearn.log_model(rf_clf, \"random_forest_classifier\")\n",
    "\n",
    "        # Calculate and log the ROC AUC metric for the validation dataset\n",
    "        val_probs = rf_clf.predict_proba(val_data)[:, 1]\n",
    "        val_roc_auc = roc_auc_score(y_val, val_probs)\n",
    "        mlflow.log_metric(\"val_roc_auc\", val_roc_auc)\n",
    "\n",
    "        # Print the ROC AUC score for the validation dataset\n",
    "        print(f\"ROC AUC en el conjunto de validación: {val_roc_auc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC en el conjunto de validación: 0.7151\n"
     ]
    }
   ],
   "source": [
    "# Ejemplo de uso de la función\n",
    "train_and_log_model(train_data, y_train, val_data, y_val, n_estimators=60, max_depth=5, random_state=42, run_name=\"RandomForestClassifier\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC en el conjunto de validación: 0.7047\n",
      "ROC AUC en el conjunto de validación: 0.7122\n",
      "ROC AUC en el conjunto de validación: 0.7117\n",
      "ROC AUC en el conjunto de validación: 0.7145\n",
      "ROC AUC en el conjunto de validación: 0.7171\n",
      "ROC AUC en el conjunto de validación: 0.7218\n",
      "ROC AUC en el conjunto de validación: 0.7245\n"
     ]
    }
   ],
   "source": [
    "list_max_depth_case = [1,2,3,4,5,6,7]\n",
    "\n",
    "for i in list_max_depth_case:\n",
    "    train_and_log_model(train_data, y_train, val_data, y_val, n_estimators=100, max_depth= i, random_state=42, run_name=\"RandomForestClassifier\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random search - RFC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def train_and_log_model(train_data, y_train, val_data, y_val, n_iter, cv, random_state,\n",
    "                        n_estimators_range, max_depth_range, min_samples_split_values,\n",
    "                        min_samples_leaf_values, bootstrap_values, run_name=\"RandomizedSearchCV\"):\n",
    "    \n",
    "    param_grid = {\n",
    "        \"n_estimators\": n_estimators_range,\n",
    "        \"max_depth\": max_depth_range,\n",
    "        \"min_samples_split\": min_samples_split_values,\n",
    "        \"min_samples_leaf\": min_samples_leaf_values,\n",
    "        \"bootstrap\": bootstrap_values,\n",
    "    }\n",
    "\n",
    "    rf_random = RandomizedSearchCV(\n",
    "        estimator=RandomForestClassifier(),\n",
    "        param_distributions=param_grid,\n",
    "        n_iter=n_iter,\n",
    "        cv=cv,\n",
    "        verbose=2,\n",
    "        random_state=random_state,\n",
    "    )\n",
    "\n",
    "    with mlflow.start_run(run_name=run_name):\n",
    "        rf_random.fit(train_data, y_train)\n",
    "\n",
    "        best_params = rf_random.best_params_\n",
    "        best_rf_clf = rf_random.best_estimator_\n",
    "\n",
    "        # Log parameters\n",
    "        mlflow.log_param(\"Model\", run_name)\n",
    "        for param, value in best_params.items():\n",
    "            mlflow.log_param(param, value)\n",
    "\n",
    "        # Calcular y registrar la métrica de precisión\n",
    "        train_preds = best_rf_clf.predict(train_data)\n",
    "        train_accuracy = accuracy_score(y_train, train_preds)\n",
    "        mlflow.log_metric(\"train_accuracy\", train_accuracy)\n",
    "\n",
    "        # Calcular y registrar el ROC AUC para el conjunto de entrenamiento\n",
    "        train_probs = best_rf_clf.predict_proba(train_data)[:, 1]\n",
    "        train_roc_auc = roc_auc_score(y_train, train_probs)\n",
    "        mlflow.log_metric(\"train_roc_auc\", train_roc_auc)\n",
    "\n",
    "        # Registrar el modelo\n",
    "        mlflow.sklearn.log_model(best_rf_clf, \"random_forest_classifier\")\n",
    "\n",
    "        # Calcular y registrar el ROC AUC para el conjunto de validación\n",
    "        val_probs = best_rf_clf.predict_proba(val_data)[:, 1]\n",
    "        val_roc_auc = roc_auc_score(y_val, val_probs)\n",
    "        mlflow.log_metric(\"val_roc_auc\", val_roc_auc)\n",
    "\n",
    "        print(f\"ROC AUC en el conjunto de validación: {val_roc_auc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 2 candidates, totalling 4 fits\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=273; total time= 1.3min\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=273; total time= 1.3min\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=1, min_samples_split=2, n_estimators=1485; total time=12.2min\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=1, min_samples_split=2, n_estimators=1485; total time=11.2min\n",
      "ROC AUC en el conjunto de validación: 0.7324\n"
     ]
    }
   ],
   "source": [
    "# Ejemplo de uso de la función\n",
    "n_estimators_range = [int(x) for x in np.linspace(start=200, stop=2000, num=50)]\n",
    "max_depth_range = [int(x) for x in np.linspace(10, 50, num=5)]\n",
    "min_samples_split_values = [2, 5]\n",
    "min_samples_leaf_values = [1, 2]\n",
    "bootstrap_values = [True]\n",
    "\n",
    "train_and_log_model(train_data, y_train, val_data, y_val, n_iter=2, cv=2, random_state=42,\n",
    "                    n_estimators_range=n_estimators_range, max_depth_range=max_depth_range,\n",
    "                    min_samples_split_values=min_samples_split_values, min_samples_leaf_values=min_samples_leaf_values,\n",
    "                    bootstrap_values=bootstrap_values)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid search - RFC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 1000 candidates, totalling 2000 fits\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "def train_and_log_model(train_data, y_train, val_data, y_val, cv, random_state,\n",
    "                        n_estimators_range, max_depth_range, min_samples_split_values,\n",
    "                        min_samples_leaf_values, bootstrap_values, run_name=\"GridSearchCV\"):\n",
    "    \n",
    "    param_grid = {\n",
    "        \"n_estimators\": n_estimators_range,\n",
    "        \"max_depth\": max_depth_range,\n",
    "        \"min_samples_split\": min_samples_split_values,\n",
    "        \"min_samples_leaf\": min_samples_leaf_values,\n",
    "        \"bootstrap\": bootstrap_values,\n",
    "    }\n",
    "\n",
    "    rf_grid = GridSearchCV(\n",
    "        estimator=RandomForestClassifier(),\n",
    "        param_grid=param_grid,\n",
    "        cv=cv,\n",
    "        verbose=2,\n",
    "        n_jobs=-1,\n",
    "    )\n",
    "\n",
    "    with mlflow.start_run(run_name=run_name):\n",
    "        rf_grid.fit(train_data, y_train)\n",
    "\n",
    "        best_params = rf_grid.best_params_\n",
    "        best_rf_clf = rf_grid.best_estimator_\n",
    "\n",
    "        # Log parameters\n",
    "        for param, value in best_params.items():\n",
    "            mlflow.log_param(param, value)\n",
    "\n",
    "        # Calcular y registrar la métrica de precisión en el conjunto de entrenamiento\n",
    "        train_preds = best_rf_clf.predict(train_data)\n",
    "        train_accuracy = accuracy_score(y_train, train_preds)\n",
    "        mlflow.log_metric(\"train_accuracy\", train_accuracy)\n",
    "\n",
    "        # Calcular y registrar el ROC AUC para el conjunto de entrenamiento\n",
    "        train_probs = best_rf_clf.predict_proba(train_data)[:, 1]\n",
    "        train_roc_auc = roc_auc_score(y_train, train_probs)\n",
    "        mlflow.log_metric(\"train_roc_auc\", train_roc_auc)\n",
    "\n",
    "        # Calcular y registrar la métrica de precisión en el conjunto de validación\n",
    "        val_preds = best_rf_clf.predict(val_data)\n",
    "        val_accuracy = accuracy_score(y_val, val_preds)\n",
    "        mlflow.log_metric(\"val_accuracy\", val_accuracy)\n",
    "\n",
    "        # Calcular y registrar el ROC AUC para el conjunto de validación\n",
    "        val_probs = best_rf_clf.predict_proba(val_data)[:, 1]\n",
    "        val_roc_auc = roc_auc_score(y_val, val_probs)\n",
    "        mlflow.log_metric(\"val_roc_auc\", val_roc_auc)\n",
    "\n",
    "        # Registrar el modelo\n",
    "        mlflow.sklearn.log_model(best_rf_clf, \"random_forest_classifier\")\n",
    "\n",
    "        print(f\"ROC AUC en el conjunto de validación: {val_roc_auc:.4f}\")\n",
    "\n",
    "# Ejemplo de uso de la función\n",
    "n_estimators_range = [int(x) for x in np.linspace(start=200, stop=400, num=100)]\n",
    "max_depth_range = [int(x) for x in np.linspace(10, 30, num=15)]\n",
    "min_samples_split_values = [2, 5]\n",
    "min_samples_leaf_values = [1, 2]\n",
    "bootstrap_values = [True]\n",
    "\n",
    "train_and_log_model(train_data, y_train, val_data, y_val, cv=2, random_state=42,\n",
    "                    n_estimators_range=n_estimators_range, max_depth_range=max_depth_range,\n",
    "                    min_samples_split_values=min_samples_split_values, min_samples_leaf_values=min_samples_leaf_values,\n",
    "                    bootstrap_values=bootstrap_values)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train_and_log_lightgbm(train_data, y_train, val_data, y_val, params, run_name=\"LightGBM\"):\n",
    "    \n",
    "    with mlflow.start_run(run_name=run_name):\n",
    "\n",
    "        # Crear el conjunto de datos de LightGBM\n",
    "        lgb_train_data = lgb.Dataset(train_data, label=y_train)\n",
    "        lgb_val_data = lgb.Dataset(val_data, label=y_val, reference=lgb_train_data)\n",
    "\n",
    "        mlflow.log_param(\"Model\", run_name)\n",
    "\n",
    "        # Entrenar el modelo LightGBM\n",
    "        lgb_model = lgb.train(params, lgb_train_data, valid_sets=lgb_val_data)\n",
    "\n",
    "        # Log parameters\n",
    "        for param, value in params.items():\n",
    "            mlflow.log_param(param, value)\n",
    "\n",
    "        # Calcular y registrar la métrica de precisión en el conjunto de entrenamiento\n",
    "        train_preds = np.round(lgb_model.predict(train_data))\n",
    "        train_accuracy = accuracy_score(y_train, train_preds)\n",
    "        mlflow.log_metric(\"train_accuracy\", train_accuracy)\n",
    "\n",
    "        # Calcular y registrar el ROC AUC para el conjunto de entrenamiento\n",
    "        train_probs = lgb_model.predict(train_data)\n",
    "        train_roc_auc = roc_auc_score(y_train, train_probs)\n",
    "        mlflow.log_metric(\"train_roc_auc\", train_roc_auc)\n",
    "\n",
    "        # Calcular y registrar la métrica de precisión en el conjunto de validación\n",
    "        val_preds = np.round(lgb_model.predict(val_data))\n",
    "        val_accuracy = accuracy_score(y_val, val_preds)\n",
    "        mlflow.log_metric(\"val_accuracy\", val_accuracy)\n",
    "\n",
    "        # Calcular y registrar el ROC AUC para el conjunto de validación\n",
    "        val_probs = lgb_model.predict(val_data)\n",
    "        val_roc_auc = roc_auc_score(y_val, val_probs)\n",
    "        mlflow.log_metric(\"val_roc_auc\", val_roc_auc)\n",
    "\n",
    "        # Registrar el modelo\n",
    "        mlflow.lightgbm.log_model(lgb_model, \"lightgbm\")\n",
    "\n",
    "        print(f\"ROC AUC en el conjunto de validación: {val_roc_auc:.4f}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "params = {\n",
    "    \"objective\": \"binary\",\n",
    "    \"metric\": \"auc\",\n",
    "    \"boosting_type\": \"gbdt\",\n",
    "    \"num_leaves\": 5,\n",
    "    \"learning_rate\": 0.05,\n",
    "    \"feature_fraction\": 0.9,\n",
    "}\n",
    "\n",
    "train_and_log_lightgbm(train_data, y_train, val_data, y_val, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train_and_log_xgboost(train_data, y_train, val_data, y_val, params, run_name=\"XGBoost\", artifact_path=\"artifact\"):\n",
    "    \n",
    "    with mlflow.start_run(run_name=run_name):\n",
    "\n",
    "        # Crear el conjunto de datos de XGBoost\n",
    "        xgb_train_data = xgb.DMatrix(train_data, label=y_train)\n",
    "        xgb_val_data = xgb.DMatrix(val_data, label=y_val)\n",
    "\n",
    "        # Entrenar el modelo XGBoost\n",
    "        xgb_model = xgb.train(params, xgb_train_data, evals=[(xgb_val_data, 'validation')])\n",
    "\n",
    "        # Log parameters\n",
    "        for param, value in params.items():\n",
    "            mlflow.log_param(param, value)\n",
    "\n",
    "        # Registrar el nombre del modelo\n",
    "        mlflow.log_param(\"Model\", run_name)\n",
    "\n",
    "        # Calcular y registrar la métrica de precisión en el conjunto de entrenamiento\n",
    "        train_preds = np.round(xgb_model.predict(xgb_train_data))\n",
    "        train_accuracy = accuracy_score(y_train, train_preds)\n",
    "        mlflow.log_metric(\"train_accuracy\", train_accuracy)\n",
    "\n",
    "        # Calcular y registrar el ROC AUC para el conjunto de entrenamiento\n",
    "        train_probs = xgb_model.predict(xgb_train_data)\n",
    "        train_roc_auc = roc_auc_score(y_train, train_probs)\n",
    "        mlflow.log_metric(\"train_roc_auc\", train_roc_auc)\n",
    "\n",
    "        # Calcular y registrar la métrica de precisión en el conjunto de validación\n",
    "        val_preds = np.round(xgb_model.predict(xgb_val_data))\n",
    "        val_accuracy = accuracy_score(y_val, val_preds)\n",
    "        mlflow.log_metric(\"val_accuracy\", val_accuracy)\n",
    "\n",
    "        # Calcular y registrar el ROC AUC para el conjunto de validación\n",
    "        val_probs = xgb_model.predict(xgb_val_data)\n",
    "        val_roc_auc = roc_auc_score(y_val, val_probs)\n",
    "        mlflow.log_metric(\"val_roc_auc\", val_roc_auc)\n",
    "\n",
    "        # Registrar el modelo\n",
    "        mlflow.xgboost.log_model(xgb_model, \"xgboost\")\n",
    "\n",
    "        # Guardar artefacto\n",
    "        os.makedirs(artifact_path, exist_ok=True)\n",
    "        \n",
    "        # Crear y guardar la matriz de confusión como imagen\n",
    "        cm = confusion_matrix(y_val, val_preds)\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
    "        plt.ylabel(\"True label\")\n",
    "        plt.xlabel(\"Predicted label\")\n",
    "        plt.title(\"Matriz de confusión\")\n",
    "        confusion_matrix_path = os.path.join(artifact_path, \"confusion_matrix.png\")\n",
    "        plt.savefig(confusion_matrix_path)\n",
    "        plt.close()\n",
    "\n",
    "        mlflow.log_artifacts(artifact_path)\n",
    "\n",
    "        # Eliminar el directorio del artefacto local después de registrar\n",
    "        shutil.rmtree(artifact_path)\n",
    "\n",
    "        print(f\"ROC AUC en el conjunto de validación: {val_roc_auc:.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "# Ejemplo de uso de la función\n",
    "params = {\n",
    "    \"objective\": \"binary:logistic\",\n",
    "    \"eval_metric\": \"auc\",\n",
    "        \"max_depth\": 6,\n",
    "    \"eta\": 0.3,\n",
    "    \"silent\": 1,\n",
    "}\n",
    "\n",
    "train_and_log_xgboost(train_data, y_train, val_data, y_val, params)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imagenes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "import os\n",
    "import sys\n",
    "\n",
    "\n",
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from src import data_utils, models, config\n",
    "\n",
    "# # /////////////////////////////////////////////////////////////////////////////////////////////\n",
    "\n",
    "from src import class_Experiment\n",
    "from src.class_Experiment import registrar_experiment\n",
    "from src import models, data_utils, config\n",
    "\n",
    "# /////////////////////////////////////////////////////////////////////////////////////////////\n",
    "\n",
    "DATASET_FOLDER = config.DATASET_FILENAME_IMAGE\n",
    "\n",
    "img_height = 224\n",
    "img_width = 224\n",
    "channels = 3\n",
    "batch_size = 32\n",
    "num_classes = 25\n",
    "\n",
    "input_shape = (img_height, img_width, channels)\n",
    "\n",
    "# Load train and test datasets\n",
    "train_ds = keras.preprocessing.image_dataset_from_directory(\n",
    "    directory=os.path.join(DATASET_FOLDER, \"train\"),\n",
    "    labels=\"inferred\",\n",
    "    label_mode=\"categorical\",\n",
    "    seed=123,\n",
    "    image_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    ")\n",
    "\n",
    "test_ds = keras.preprocessing.image_dataset_from_directory(\n",
    "    directory=os.path.join(DATASET_FOLDER, \"test\"),\n",
    "    labels=\"inferred\",\n",
    "    label_mode=\"categorical\",\n",
    "    seed=123,\n",
    "    image_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    ")\n",
    "\n",
    "class_names = train_ds.class_names\n",
    "print(class_names)\n",
    "\n",
    "assert len(class_names) == 25\n",
    "\n",
    "\n",
    "# Configure data loader for performance\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "train_ds = train_ds.cache().shuffle(1000).prefetch(buffer_size=AUTOTUNE)\n",
    "test_ds = test_ds.cache().prefetch(buffer_size=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " efficientnetb0 (Functional)  (None, 7, 7, 1280)       4049571   \n",
      "                                                                 \n",
      " flatten_5 (Flatten)         (None, 62720)             0         \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 25)                1568025   \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 5,617,596\n",
      "Trainable params: 1,568,025\n",
      "Non-trainable params: 4,049,571\n",
      "_________________________________________________________________\n",
      "None\n",
      "Found 1875 images belonging to 25 classes.\n",
      "Found 7509 images belonging to 25 classes.\n",
      "WARNING:tensorflow:Model failed to serialize as JSON. Ignoring... Unable to serialize [2.0896919 2.1128857 2.1081853] to JSON. Unrecognized type <class 'tensorflow.python.framework.ops.EagerTensor'>.\n",
      "Epoch 1/20\n",
      "235/235 [==============================] - 80s 313ms/step - loss: 3.3650 - accuracy: 0.5804 - val_loss: 2.5203 - val_accuracy: 0.7088\n",
      "Epoch 2/20\n",
      "235/235 [==============================] - 74s 316ms/step - loss: 1.4637 - accuracy: 0.8109 - val_loss: 2.3167 - val_accuracy: 0.7627\n",
      "Epoch 3/20\n",
      "235/235 [==============================] - 77s 326ms/step - loss: 1.1302 - accuracy: 0.8590 - val_loss: 2.9148 - val_accuracy: 0.7461\n",
      "Epoch 4/20\n",
      "235/235 [==============================] - 74s 315ms/step - loss: 1.0034 - accuracy: 0.8833 - val_loss: 2.6062 - val_accuracy: 0.7872\n",
      "Epoch 5/20\n",
      "235/235 [==============================] - 70s 296ms/step - loss: 0.9024 - accuracy: 0.8995 - val_loss: 2.6245 - val_accuracy: 0.8085\n",
      "Epoch 6/20\n",
      "235/235 [==============================] - 70s 296ms/step - loss: 0.6728 - accuracy: 0.9189 - val_loss: 2.9149 - val_accuracy: 0.7909\n",
      "Epoch 7/20\n",
      "235/235 [==============================] - 71s 302ms/step - loss: 0.6675 - accuracy: 0.9272 - val_loss: 3.1267 - val_accuracy: 0.7872\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Params for the experiment\n",
    "experiment_params = {\n",
    "    \"experiment_name\": \"CV\",\n",
    "    \"model_name\": \"efficientnet_B0\",\n",
    "    \"input_shape\": input_shape,\n",
    "    \"dropout\": 0.15,\n",
    "    \"num_classes\": len(class_names),\n",
    "    \"ruta_carpeta_train\": os.path.join(DATASET_FOLDER, \"train\"),\n",
    "    \"ruta_carpeta_test\": os.path.join(DATASET_FOLDER, \"test\"),\n",
    "    \"batch_size\": 32,\n",
    "    \"epochs\": 20,\n",
    "    \"data_augmentation\": True,\n",
    "    \"additional_layers\": 0,\n",
    "    \"neurons_per_layer\": [32],\n",
    "    \"hyperparameters\": {\n",
    "        \"optimizer\": \"adam\",\n",
    "        \"loss\": \"categorical_crossentropy\",\n",
    "        \"batch_size\": 32,\n",
    "        \"epochs\": 20,\n",
    "    },\n",
    "    \"metrics\": {\n",
    "        \"accuracy\": \"accuracy\",\n",
    "    },\n",
    "    \"augmentation_params\": {\n",
    "        \"rotation_range\": 10,\n",
    "        \"width_shift_range\": 0,\n",
    "        \"height_shift_range\": 0,\n",
    "        \"shear_range\": 0.1,\n",
    "        \"zoom_range\": 0.1,\n",
    "        \"horizontal_flip\": True,\n",
    "        \"fill_mode\": \"nearest\",\n",
    "    }\n",
    "}\n",
    "\n",
    "model = models.create_efficientnet_model_compiled(\n",
    "    version=0,\n",
    "    input_shape=experiment_params[\"input_shape\"],\n",
    "    debug=True,\n",
    "    dropout=experiment_params[\"dropout\"],\n",
    "    num_classes=experiment_params[\"num_classes\"],\n",
    "    additional_layers=experiment_params[\"additional_layers\"],\n",
    "    neurons_per_layer=experiment_params[\"neurons_per_layer\"]\n",
    "\n",
    ")\n",
    "\n",
    "experiment = class_Experiment.Experiment(\n",
    "    experiment_name=experiment_params[\"experiment_name\"],\n",
    "    model_name=experiment_params[\"model_name\"],\n",
    "    model=model,\n",
    "    hyperparameters=experiment_params[\"hyperparameters\"],\n",
    "    metrics=experiment_params[\"metrics\"],\n",
    "    ruta_carpeta_train=experiment_params[\"ruta_carpeta_train\"],\n",
    "    ruta_carpeta_test=experiment_params[\"ruta_carpeta_test\"],\n",
    "    batch_size=experiment_params[\"batch_size\"],\n",
    "    epochs=experiment_params[\"epochs\"],\n",
    "    data_augmentation=experiment_params[\"data_augmentation\"],\n",
    "    **experiment_params[\"augmentation_params\"]\n",
    ")\n",
    "\n",
    "class_Experiment.registrar_experiment(experiment, experiment_params[\"experiment_name\"])\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpu_base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
